{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chubby-vegetation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T05:10:57.451542Z",
     "start_time": "2021-02-16T05:10:57.210281Z"
    }
   },
   "outputs": [],
   "source": [
    "import testFunctions as tf\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "catholic-ecology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T05:12:26.951262Z",
     "start_time": "2021-02-16T05:10:57.452670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to your RDS database...\n",
      "Reading tables...\n",
      "Done!\n",
      "Closed engine.\n",
      "The number of books in the train set: 10000, test set: 9999, val set: 9998. The number of users in the train set: 53424, test set: 26712, val set: 26712.\n"
     ]
    }
   ],
   "source": [
    "pipeline = tf.MSEPipeline()\n",
    "pipeline.preprocess()\n",
    "train, test, validation = pipeline.split_test_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-digest",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FROM  [here](https://towardsdatascience.com/recommender-systems-matrix-factorization-using-pytorch-bd52f46aa199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-seeking",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:35.998Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_params(df):\n",
    "    \n",
    "    uids = df.uid.unique().tolist()\n",
    "    iids = df.iid.unique().tolist()\n",
    "    num_uid = len(uids)\n",
    "    num_iid = len(iids)\n",
    "    \n",
    "    return uids, iids, num_uid, num_iid\n",
    "\n",
    "def create_embeddings(n, K, gamma = 7):\n",
    "    \"\"\"\n",
    "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
    "    n: number of items/users\n",
    "    K: number of factors in the embedding \n",
    "    \"\"\"\n",
    "    return gamma*np.random.rand(n, K) / K\n",
    "\n",
    "def create_sparse_matrix(df, rows, cols, column_name=\"rating\"):\n",
    "    \"\"\" Returns a sparse utility matrix\"\"\" \n",
    "    return sparse.csc_matrix((df[column_name].values,(df['uid'].values, df['iid'].values)),shape=(rows, cols))\n",
    "\n",
    "def predict(df, emb_user, emb_anime):\n",
    "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
    "    \n",
    "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
    "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
    "    \"\"\"\n",
    "    df['prediction'] = np.sum(np.multiply(emb_anime[df['iid']],emb_user[df['uid']]), axis=1)\n",
    "    return df\n",
    "\n",
    "def cost(df, emb_user, emb_anime):\n",
    "    \"\"\" Computes mean square error\"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_anime), emb_user.shape[0], emb_anime.shape[0], 'prediction')\n",
    "    return np.sum((Y-predicted).power(2))/df.shape[0]\n",
    "\n",
    "def gradient(df, emb_user, emb_anime):\n",
    "    \"\"\" Computes the gradient for user and anime embeddings\"\"\"\n",
    "    lmbda = 0.002\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_anime), emb_user.shape[0], emb_anime.shape[0], 'prediction')\n",
    "    delta =(Y-predicted)\n",
    "    grad_user = (-2/df.shape[0])*(delta*emb_anime) + 2*lmbda*emb_user\n",
    "    grad_anime = (-2/df.shape[0])*(delta.T*emb_user) + 2*lmbda*emb_anime\n",
    "    return grad_user, grad_anime\n",
    "\n",
    "def gradient_descent(df, emb_user, emb_anime, iterations=200, learning_rate=0.05, df_val=None, beta = 0.9, updates = True):\n",
    "    \"\"\" \n",
    "    Computes gradient descent with momentum (0.9) for given number of iterations.\n",
    "    emb_user: the trained user embedding\n",
    "    emb_anime: the trained anime embedding\n",
    "    \"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    grad_user, grad_anime = gradient(df, emb_user, emb_anime)\n",
    "    v_user = grad_user\n",
    "    v_anime = grad_anime\n",
    "    for i in range(iterations):\n",
    "        grad_user, grad_anime = gradient(df, emb_user, emb_anime)\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_anime = beta*v_anime + (1-beta)*grad_anime\n",
    "        emb_user = emb_user - learning_rate*v_user\n",
    "        emb_anime = emb_anime - learning_rate*v_anime\n",
    "        if(not (i+1)%50) and (updates):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  cost(df, emb_user, emb_anime))\n",
    "            if df_val is not None:\n",
    "                print(\"validation mse:\",  cost(df_val, emb_user, emb_anime))\n",
    "    return emb_user, emb_anime, cost(df, emb_user, emb_anime), cost(df_val, emb_user, emb_anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-queensland",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:36.353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uids, iids, num_uid, num_iid = get_params(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-franchise",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:36.708Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Y = create_sparse_matrix(train, num_uid, num_iid)\n",
    "Y.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-business",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:37.044Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_user = create_embeddings(num_uid, 4)\n",
    "emb_anime = create_embeddings(num_iid, 4)\n",
    "emb_user, emb_anime = gradient_descent(train, emb_user, emb_anime, iterations=350, learning_rate=0.1, df_val = validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-parade",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:37.358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def sample_hyperparameters():\n",
    "\n",
    "    return {\n",
    "        \"K\": np.random.randint(10, 20),\n",
    "        \"lr\": np.random.normal(0.05, 0.025),\n",
    "        \"beta\": np.random.normal(0.9, 0.05),\n",
    "        \"gamma\": np.random.randint(5, 15),\n",
    "        \"epochs\": np.random.randint(50, 80)\n",
    "        }      \n",
    "def paramSearch(train, num_uid, num_iid, num_samples = 5):\n",
    "\n",
    "        hyperparams = pd.DataFrame()\n",
    "        print('Searching for optimal parameters...')\n",
    "        for i in tqdm(range(num_samples)):\n",
    "            # get a random sample of hyperparameters\n",
    "            params = sample_hyperparameters()\n",
    "            print(params)\n",
    "            # train a model using those hyperparameters\n",
    "            emb_user = create_embeddings(num_uid, params['K'], gamma = params['gamma'])\n",
    "            emb_item = create_embeddings(num_iid, params['K'], gamma = params['gamma'])\n",
    "            emb_user, emb_item, cost_train, cost_val = gradient_descent(train, \n",
    "                                                                         emb_user, \n",
    "                                                                         emb_item, \n",
    "                                                                         iterations=params['epochs'], \n",
    "                                                                         learning_rate=params['lr'],\n",
    "                                                                         beta = params['beta'], \n",
    "                                                                         df_val = validation,\n",
    "                                                                         updates = False)\n",
    "            params['train_mse'] = cost_train\n",
    "            params['val_mse'] = cost_val\n",
    "            hyperparams = hyperparams.append(params, ignore_index=True)\n",
    "        return hyperparams.sort_values(by = 'val_mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dimensional-convention",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for optimal parameters...\n",
      "{'K': 16, 'lr': 0.06911681421964877, 'beta': 0.8751939500399427, 'gamma': 5, 'epochs': 53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [01:12<10:52, 72.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 14, 'lr': 0.059983531559637523, 'beta': 0.9299892557964924, 'gamma': 6, 'epochs': 79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [02:49<10:38, 79.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 10, 'lr': 0.04015033453193613, 'beta': 0.9194450312942336, 'gamma': 13, 'epochs': 59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [03:54<08:48, 75.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 13, 'lr': 0.061889367038880476, 'beta': 1.0124316673343328, 'gamma': 7, 'epochs': 57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [05:05<07:24, 74.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 18, 'lr': 0.09124107449615401, 'beta': 0.9154476785848042, 'gamma': 5, 'epochs': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [06:39<06:40, 80.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 12, 'lr': 0.09134714584730058, 'beta': 0.8747537042415194, 'gamma': 5, 'epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [07:38<04:54, 73.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 15, 'lr': 0.022424125657719913, 'beta': 0.895327792394344, 'gamma': 14, 'epochs': 58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [08:56<03:44, 74.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 12, 'lr': 0.039828263821539006, 'beta': 0.8090874407948825, 'gamma': 11, 'epochs': 66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [10:13<02:31, 75.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 15, 'lr': 0.04029155477339579, 'beta': 0.8854276678463482, 'gamma': 14, 'epochs': 77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [11:55<01:23, 83.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 18, 'lr': 0.01829605681505877, 'beta': 0.8838056958032741, 'gamma': 11, 'epochs': 76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:48<00:00, 82.86s/it]\n"
     ]
    }
   ],
   "source": [
    "hp = paramSearch(train, num_uid, num_iid, num_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "irish-norwegian",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>beta</th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.895328</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>1.955910</td>\n",
       "      <td>1.955168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.885428</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.040292</td>\n",
       "      <td>2.040690</td>\n",
       "      <td>2.043973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.919445</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.040150</td>\n",
       "      <td>2.360247</td>\n",
       "      <td>2.369465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.809087</td>\n",
       "      <td>66.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.039828</td>\n",
       "      <td>3.476850</td>\n",
       "      <td>3.468857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.883806</td>\n",
       "      <td>76.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>6.176782</td>\n",
       "      <td>6.153494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.012432</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>10.005748</td>\n",
       "      <td>9.978112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.929989</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.059984</td>\n",
       "      <td>11.811594</td>\n",
       "      <td>11.785822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.091347</td>\n",
       "      <td>12.618779</td>\n",
       "      <td>12.587218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.875194</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>13.479378</td>\n",
       "      <td>13.445336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.915448</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>13.801077</td>\n",
       "      <td>13.768661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      K      beta  epochs  gamma        lr  train_mse    val_mse\n",
       "6  15.0  0.895328    58.0   14.0  0.022424   1.955910   1.955168\n",
       "8  15.0  0.885428    77.0   14.0  0.040292   2.040690   2.043973\n",
       "2  10.0  0.919445    59.0   13.0  0.040150   2.360247   2.369465\n",
       "7  12.0  0.809087    66.0   11.0  0.039828   3.476850   3.468857\n",
       "9  18.0  0.883806    76.0   11.0  0.018296   6.176782   6.153494\n",
       "3  13.0  1.012432    57.0    7.0  0.061889  10.005748   9.978112\n",
       "1  14.0  0.929989    79.0    6.0  0.059984  11.811594  11.785822\n",
       "5  12.0  0.874754    50.0    5.0  0.091347  12.618779  12.587218\n",
       "0  16.0  0.875194    53.0    5.0  0.069117  13.479378  13.445336\n",
       "4  18.0  0.915448    64.0    5.0  0.091241  13.801077  13.768661"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "studied-findings",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  iid  rating\n",
       "0    1    1       4\n",
       "1    1    4       5\n",
       "2    4    7       1\n",
       "3    7    2       4\n",
       "4    7    1       2\n",
       "5    9    9       4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testList = [\n",
    "    [1,1,4],\n",
    "    [1,4,5],\n",
    "    [4,7,1],\n",
    "    [7,2,4],\n",
    "    [7,1,2],\n",
    "    [9,9,4]\n",
    "]\n",
    "\n",
    "vec = [np.random.randint(1,10) for _ in range(10)]\n",
    "\n",
    "testListdf = pd.DataFrame(testList, columns = ['uid', 'iid', 'rating'])\n",
    "testListdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fitted-landscape",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 5, 7, 2, 9, 1, 7, 9, 6]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "stretch-territory",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testSparse = sparse.csc_matrix((testListdf['rating'].values,(testListdf['uid'].values, testListdf['iid'].values)),shape=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "center-moldova",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 26,  0,  0,  7,  0,  0, 28,  0, 24])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSparse.dot(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-translation",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## My own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "independent-porcelain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T00:52:52.137188Z",
     "start_time": "2021-02-16T00:52:52.085242Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 10000 books and 53424  users.\n"
     ]
    }
   ],
   "source": [
    "num_items = len(train.iid.unique())\n",
    "num_users = len(train.uid.unique())\n",
    "\n",
    "print(f\"The training set has {num_items} books and {num_users}  users.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-federation",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Step 1\n",
    "\n",
    "First I want to create the matrices with which I can perform gradient descent. I'll need \n",
    "   1. Feature embeddings $\\bf{A}$ and $\\bf{B}$, initialized randomly.\n",
    "   2. A sparse user-item interaction matrix $\\bf{Y}$ (also known as the utility matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "solar-union",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T01:47:23.980920Z",
     "start_time": "2021-02-16T01:47:23.671017Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for now let's just have 10 features (K=10)\n",
    "K=10 # this is a hyperparameter that should be tuned\n",
    "alpha=11 # this is a hyperparameter that should be tuned\n",
    "\n",
    "user_features = np.random.uniform(0,alpha/K,(num_users,K))\n",
    "item_features = np.random.uniform(0,alpha/K,(num_items,K))\n",
    "\n",
    "utility = sparse.csc_matrix((train.rating.values, (train.uid.values, train.iid.values)), shape=(num_users, num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-preview",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T01:01:53.297298Z",
     "start_time": "2021-02-16T01:01:53.292161Z"
    },
    "hidden": true
   },
   "source": [
    "### Step 2\n",
    "\n",
    "Now we need a cost function and it's gradient. Let's go with mean square error (MSE) for now. For us MSE looks like\n",
    "\n",
    "$$ \\textbf{MSE} = \\frac{1}{N}\\sum_{i,j}^{N} (y_{ij} - a_{ik}b_{kj})^2 $$ \n",
    "\n",
    "where $N$ is the number of non-null entries in the utility matrix. Note that the lower case names of the utility and embedded matrices represent the indexed entries of each matrix. Capital and bolded letters indicate a matrix representation of the objects. Repeated indices imply summation. \n",
    "\n",
    "If we include regularization in this loss function, we get:\n",
    "\n",
    "$$ \\textbf{L} = \\textbf{MSE} + \\lambda_a a_{\\ell m}a_{m \\ell} +  \\lambda_b b_{\\ell m}b_{m \\ell} $$. \n",
    "\n",
    "Where $\\lambda_a$ and $\\lambda_b$ are just regularization parameters. As it turns out, the matrix $\\bf{A} \\bf{B}^{T}$ is a large matrix. We can avoid computing it by just computing each prediction row individually and adding it to the training DataFrame as a new column, then we can create a sparse matrix from that! Just as in [here](https://towardsdatascience.com/recommender-systems-matrix-factorization-using-pytorch-bd52f46aa199). In fact, our `predict` method will be more or less the same. The gradient of this function is fairly simple to compute:\n",
    "\n",
    "$$ \\vec{\\nabla} \\textbf{L} = -2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "waiting-console",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:43:44.254523Z",
     "start_time": "2021-02-16T03:43:44.246238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict(df, user_features, item_features):\n",
    "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
    "    \n",
    "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
    "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
    "    \"\"\"\n",
    "    df['prediction'] = np.sum(np.multiply(item_features[df['iid']],user_features[df['uid']]), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def meanSquareError(df, utility, user_features, item_features):\n",
    "    '''\n",
    "    This function computes the MSE for a given set of feature matrices. Remember we never hold the \n",
    "    prediction utility matrix. We add a prediction column to the pandas dataframe then create a sparse\n",
    "    matrix of predictions when we need it.\n",
    "    '''\n",
    "    temp = predict(train, user_features=user_features, item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                       shape=(user_features.shape[0], item_features.shape[0]))\n",
    "    error = utility-prediction\n",
    "    return (1/len(df))*np.sum(error.power(2))\n",
    "\n",
    "def gradient_reg(df, utility, user_features, item_features, lmbda_a, lmbda_b):\n",
    "    '''\n",
    "    This function computes the regularized gradient.\n",
    "    '''\n",
    "    temp = predict(train, user_features=user_features, item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                       shape=(user_features.shape[0], item_features.shape[0]))\n",
    "    error = utility-prediction\n",
    "    grad_user = (-2/df.shape[0])*(error*item_features) + 2*lmbda_a*user_features\n",
    "    grad_item = (-2/df.shape[0])*((error.T)*user_features) + 2*lmbda_b*item_features\n",
    "    return grad_user, grad_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "happy-shell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:30:50.660600Z",
     "start_time": "2021-02-16T03:30:49.772284Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5527136723429513"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = MSE(df = train, utility = utility, user_features = user_features, item_features = item_features)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "defensive-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:30:51.597614Z",
     "start_time": "2021-02-16T03:30:50.662391Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53424, 10000) (53424, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "test = gradient_reg(df = train, utility = utility, user_features = user_features, item_features = item_features,\n",
    "                   lmbda_a = 0.0002, lmbda_b=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "outstanding-regular",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:43:24.525295Z",
     "start_time": "2021-02-16T03:43:24.517632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(df, \n",
    "                    utility, \n",
    "                    user_features, \n",
    "                    item_features, \n",
    "                    lmbda_a=0.002, \n",
    "                    lmbda_b=0.002,\n",
    "                    utility_val=None, \n",
    "                    iterations=10, \n",
    "                    learning_rate=0.05, \n",
    "                    beta=0.9, \n",
    "                    updates=True):\n",
    "\n",
    "    grad_user, grad_item = gradient_reg(df=df, \n",
    "                                        utility=utility, \n",
    "                                        user_features=user_features, \n",
    "                                        item_features=item_features, \n",
    "                                        lmbda_a=lmbda_a,\n",
    "                                        lmbda_b=lmbda_b)\n",
    "    v_user = grad_user\n",
    "    v_item = grad_item\n",
    "    for i in range(iterations):\n",
    "        grad_user, grad_item = gradient_reg(df=df, \n",
    "                                            utility=utility, \n",
    "                                            user_features=user_features, \n",
    "                                            item_features=item_features, \n",
    "                                            lmbda_a=lmbda_a,\n",
    "                                            lmbda_b=lmbda_b)\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_item = beta*v_item + (1-beta)*grad_item\n",
    "        user_features = user_features - learning_rate*v_user\n",
    "        item_features = item_features - learning_rate*v_item\n",
    "        if(not (i+1) % 50) and (updates):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  meanSquareError(df, utility, user_features, item_features))\n",
    "            if utility_val is not None:\n",
    "                print(\"validation mse:\",  meanSquareError(df, utility_val, user_features, item_features))\n",
    "\n",
    "    if utility_val:\n",
    "        return user_features, item_features, meanSquareError(df, utility, user_features, item_features), meanSquareError(utility_val, user_features, item_features)\n",
    "    else:\n",
    "        return user_features, item_features, meanSquareError(df, utility, user_features, item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "social-murray",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:44:14.728270Z",
     "start_time": "2021-02-16T03:44:05.014680Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "meanSquareError() missing 1 required positional argument: 'item_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-23c939e4af93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-e1ad153e9067>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(df, utility, user_features, item_features, lmbda_a, lmbda_b, utility_val, iterations, learning_rate, beta, updates)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: meanSquareError() missing 1 required positional argument: 'item_features'"
     ]
    }
   ],
   "source": [
    "gradient_descent(df = train, utility = utility, user_features = user_features, item_features = item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-sweet",
   "metadata": {},
   "source": [
    "## My own from file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-madonna",
   "metadata": {},
   "source": [
    "### defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "competent-safety",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T06:02:44.447232Z",
     "start_time": "2021-02-16T06:02:44.421592Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_sparse_matrix(df, rows, cols, column_name=\"rating\"):\n",
    "    ''' \n",
    "    Creates a scipy sparse matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        The data that will be made a sparse matrix\n",
    "    rows : int\n",
    "        number of rows in the matrix\n",
    "    columns : int\n",
    "        number of columns in the matrix\n",
    "    column_name : \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    '''\n",
    "    return sparse.csc_matrix((df[column_name].values, (df['uid'].values, df['iid'].values)), shape=(rows, cols))\n",
    "\n",
    "\n",
    "def create_embeddings(n, K, gamma=7):\n",
    "    ''' \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    '''\n",
    "    return gamma*np.random.rand(n, K) / K\n",
    "\n",
    "def predict(df, user_features, item_features):\n",
    "    ''' \n",
    "    This function performs the element wise prediction of each item for each user. It avoids building the \n",
    "    approximated utility matrix in order to save space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas DataFrame\n",
    "        The same dataframe as inputted but with a new/updated predictions column. \n",
    "\n",
    "    '''\n",
    "    df['prediction'] = np.sum(np.multiply(\n",
    "        item_features[df['iid']], user_features[df['uid']]), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def meanSquareError(df, user_features, item_features):\n",
    "    ''' \n",
    "    Computes the mean square error on the predictions. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mse : float\n",
    "        The mean square error for the given embedding matrices. \n",
    "\n",
    "    '''\n",
    "    # we need to actually make predictions then convert those into a sparse matrix\n",
    "    utility = create_sparse_matrix(df, user_features.shape[0], item_features.shape[0])\n",
    "    temp = predict(df=df, user_features=user_features,\n",
    "                   item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                   shape=(user_features.shape[0], item_features.shape[0]))\n",
    "\n",
    "    # now let's get an error matrix then return the MSE.\n",
    "    error = utility-prediction\n",
    "    mse = (1/len(df))*np.sum(error.power(2))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def gradient_reg(df, utility, user_features, item_features, lmbda_a, lmbda_b):\n",
    "    ''' \n",
    "    Computes the regularized gradient of the mean square error. Returns the gradient\n",
    "    in the 'directions' of both embedded matrices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    utility : scipy sparse matrix\n",
    "        The sparse utility matrix of all of the ratings.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "    lmbda_a, lmbda_b : float\n",
    "        These parameters are the regularization coefficients. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grad_user : numpy array\n",
    "        gradient of the MSE, partial derivative w.r.t. the user \n",
    "    grad_item : numpy array\n",
    "        gradient of the MSE, partial derivative w.r.t. the item \n",
    "\n",
    "    '''\n",
    "    # we need to actually make predictions then convert those into a sparse matrix\n",
    "    temp = predict(df=df, user_features=user_features,\n",
    "                   item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                   shape=(user_features.shape[0], item_features.shape[0]))\n",
    "    # now let's get an error matrix\n",
    "    error = utility-prediction\n",
    "\n",
    "    # we can now compute the gradient \n",
    "    # we will compute each 'direction' separately and return them separately\n",
    "    grad_user = (-2/df.shape[0]) * (error*item_features) + 2*lmbda_a*user_features\n",
    "    grad_item = (-2/df.shape[0])*((error.T) * user_features) + 2*lmbda_b*item_features\n",
    "    return grad_user, grad_item\n",
    "\n",
    "\n",
    "def gradient_descent(df,\n",
    "                     utility,\n",
    "                     user_features,\n",
    "                     item_features,\n",
    "                     val=None,\n",
    "                     lmbda_a=0.002,\n",
    "                     lmbda_b=0.002,\n",
    "                     epochs=200,\n",
    "                     learning_rate=0.05,\n",
    "                     beta=0.9,\n",
    "                     updates=True):\n",
    "    ''' \n",
    "    Performs gradient descent to find the optimal embedded matrices. A momentum term\n",
    "    is added to arrive at the minimum sooner. This function will iterate a number of times\n",
    "    specified by the user. It will update the user every 50 epochs on how the cost function \n",
    "    looks. Finally it will return the new embedded matrices and the final cost values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    utility : scipy sparse matrix\n",
    "        The sparse utility matrix of all of the ratings.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "    val : pandas DataFrame DEFAULT=None\n",
    "        The validation set to check the algorithm against.\n",
    "    lmbda_a, lmbda_b : float, DEFAULT=0.002 for both\n",
    "        These parameters are the regularization coefficients. \n",
    "    epochs : int, DEFAULT=200\n",
    "        The number of iterations on which to perform GD\n",
    "    learning_rate : float, DEFAULT=0.05\n",
    "        The learning rate for GD.\n",
    "    beta : float, DEFAULT=0.9\n",
    "        The momentum coefficient.\n",
    "    updates: bool, DEFAULT=True\n",
    "        The option to print periodic updates of the MSE as the algorithm runs.\n",
    "        Updates will print every epoch with the MSE of the set. It will give\n",
    "        the MSE of the validation set if provided.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    user_features : numpy array\n",
    "        The optimized user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The optimized item feature embeddings.\n",
    "    mse_train : float\n",
    "        The final MSE of the training set\n",
    "    mse_val : float, OPTIONAL\n",
    "        the final MSE of the validation set\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    # get the initial gradient term so we can perform the first\n",
    "    # round of GD. Needed for momentum terms\n",
    "    grad_user, grad_item = gradient_reg(df=df,\n",
    "                                        utility=utility,\n",
    "                                        user_features=user_features,\n",
    "                                        item_features=item_features,\n",
    "                                        lmbda_a=lmbda_a,\n",
    "                                        lmbda_b=lmbda_b)\n",
    "    v_user = grad_user\n",
    "    v_item = grad_item\n",
    "    for i in range(epochs):\n",
    "        # update the gradient based on new feature matrices\n",
    "        grad_user, grad_item = gradient_reg(df=df,\n",
    "                                            utility=utility,\n",
    "                                            user_features=user_features,\n",
    "                                            item_features=item_features,\n",
    "                                            lmbda_a=lmbda_a,\n",
    "                                            lmbda_b=lmbda_b)\n",
    "\n",
    "        # compute our update matrices\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_item = beta*v_item + (1-beta)*grad_item\n",
    "\n",
    "        # update the embedded matrices\n",
    "        user_features = user_features - learning_rate*v_user\n",
    "        item_features = item_features - learning_rate*v_item\n",
    "\n",
    "        # just print out values every so often to see what is happening \n",
    "        # with the algo.\n",
    "        if(not (i+1) % 50) and (updates):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  meanSquareError(\n",
    "                df, user_features, item_features))\n",
    "            if val is not None:\n",
    "                print(\"validation mse:\",  meanSquareError(\n",
    "                    val, user_features, item_features))\n",
    "\n",
    "    # compute the final MSE\n",
    "    mse_train = meanSquareError(df, user_features, item_features)\n",
    "\n",
    "    # here we just check if the validation set is passed in so we can return the final cost of that as well if needed.\n",
    "    if val:\n",
    "        mse_val = meanSquareError(val, user_features, item_features)\n",
    "        return user_features, item_features, mse_train, mse_val\n",
    "    else:\n",
    "        return user_features, item_features, mse_train\n",
    "\n",
    "\n",
    "def sample_hyperparameters():\n",
    "    ''' \n",
    "    This function returns a random value for each hyperparameter for MSE gradient descent. \n",
    "    '''\n",
    "    return {\n",
    "        \"K\": np.random.randint(10, 20),\n",
    "        \"lr\": np.random.normal(0.05, 0.025),\n",
    "        \"beta\": np.random.normal(0.9, 0.05),\n",
    "        \"gamma\": np.random.randint(5, 15),\n",
    "        \"epochs\": np.random.randint(50, 80)\n",
    "    }\n",
    "\n",
    "\n",
    "class MSErec():\n",
    "    '''\n",
    "    This class will perform all ML processes to predict books for users of our app. It will create \n",
    "    user/item matrices, perform gradient descent (with momentum), and output predictions!\n",
    "    '''\n",
    "\n",
    "    def __init__(self, df, test=None, validation=None):\n",
    "        ''' \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "        # let's create a class dataframe object first\n",
    "        self.df=df\n",
    "        \n",
    "        num_uid = len(df.uid.unique())\n",
    "        num_iid = len(df.iid.unique())\n",
    "\n",
    "        # create sparse matrices\n",
    "        self.utility = create_sparse_matrix(df, num_uid, num_iid)\n",
    "        # only create matrices for test and val if passed\n",
    "        if test:\n",
    "            self.test = create_sparse_matrix(test, num_uid, num_iid)\n",
    "        else:\n",
    "            self.test = None\n",
    "        if validation:\n",
    "            self.validation = create_sparse_matrix(validation, num_uid, num_iid)\n",
    "        else:\n",
    "            self.validation = None\n",
    "    \n",
    "\n",
    "    def trainModel(self, K=15, beta=0.90, epochs=60, gamma=14, lr=0.025):\n",
    "        ''' \n",
    "        optimal : K=15, beta=0.90, epochs=60, gamma=14, lr=0.025\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "        # this initializes some embedding matrices\n",
    "        num_uid = self.utility.shape[0]\n",
    "        num_iid = self.utility.shape[1]\n",
    "        self.user_features = create_embeddings(num_uid, K=K, gamma=gamma)\n",
    "        self.item_features = create_embeddings(num_iid, K=K, gamma=gamma)\n",
    "        \n",
    "        # now perform GD, check if we passed a validation set as well.\n",
    "        if self.validation is not None:\n",
    "            self.emb_user, self.emb_item, cost_train, cost_val = gradient_descent(df = self.df,\n",
    "                                                                              utility = self.utility,\n",
    "                                                                              user_features = self.user_features,\n",
    "                                                                              item_features = self.item_features,\n",
    "                                                                              epochs=epochs,\n",
    "                                                                              val = self.validation,\n",
    "                                                                              updates=False)\n",
    "            return (cost_train, cost_val)\n",
    "    \n",
    "        else:\n",
    "            self.emb_user, self.emb_item, cost_train = gradient_descent(df = self.df,\n",
    "                                                                      utility = self.utility,\n",
    "                                                                      user_features = self.user_features,\n",
    "                                                                      item_features = self.item_features,\n",
    "                                                                      epochs=epochs,\n",
    "                                                                      updates=False)\n",
    "            return (cost_train,)\n",
    "\n",
    "    def paramSearch(self, num_samples=5):\n",
    "        ''' \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "        hyperparams = pd.DataFrame()\n",
    "        print('Searching for optimal parameters...')\n",
    "        for i in tqdm(range(num_samples)):\n",
    "            # get a random sample of hyperparameters\n",
    "            params = sample_hyperparameters()\n",
    "            cost = self.trainModel(K=params[\"K\"],\n",
    "                                   beta=params[\"beta\"], \n",
    "                                   epochs=params[\"epochs\"], \n",
    "                                   gamma=params[\"gamma\"], \n",
    "                                   lr=params[\"lr\"])\n",
    "            \n",
    "            params['train_mse'] = cost[0]   \n",
    "            if len(cost)==2:\n",
    "                params['val_mse'] = cost[1]\n",
    "            hyperparams = hyperparams.append(params, ignore_index=True)\n",
    "            \n",
    "        return hyperparams.sort_values(by='train_mse')\n",
    "    \n",
    "    def getPredictions(self):\n",
    "        self.df = predict(df = self.df, \n",
    "                          user_features = self.user_features, \n",
    "                          item_features = self.item_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-leader",
   "metadata": {},
   "source": [
    "### testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hazardous-standing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T06:02:45.420315Z",
     "start_time": "2021-02-16T06:02:45.092181Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MSErec(df = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "charged-living",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T06:05:22.023340Z",
     "start_time": "2021-02-16T06:02:45.923083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for optimal parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:36<00:00, 78.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>beta</th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.923736</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>6.278766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.855208</td>\n",
       "      <td>66.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045787</td>\n",
       "      <td>9.029424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      K      beta  epochs  gamma        lr  train_mse\n",
       "0  18.0  0.923736    78.0   11.0  0.043332   6.278766\n",
       "1  11.0  0.855208    66.0    7.0  0.045787   9.029424"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.paramSearch(num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "southwest-kidney",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T06:05:43.915351Z",
     "start_time": "2021-02-16T06:05:43.374314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>uid</th>\n",
       "      <th>rating</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>14930</td>\n",
       "      <td>5</td>\n",
       "      <td>1.511545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624</td>\n",
       "      <td>1747</td>\n",
       "      <td>4</td>\n",
       "      <td>0.805605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14930</td>\n",
       "      <td>3</td>\n",
       "      <td>1.210596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1747</td>\n",
       "      <td>5</td>\n",
       "      <td>1.207255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1747</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780237</th>\n",
       "      <td>780</td>\n",
       "      <td>10703</td>\n",
       "      <td>4</td>\n",
       "      <td>0.905142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780238</th>\n",
       "      <td>6500</td>\n",
       "      <td>11465</td>\n",
       "      <td>3</td>\n",
       "      <td>1.200742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780239</th>\n",
       "      <td>3408</td>\n",
       "      <td>11465</td>\n",
       "      <td>1</td>\n",
       "      <td>1.385787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780240</th>\n",
       "      <td>6778</td>\n",
       "      <td>11465</td>\n",
       "      <td>3</td>\n",
       "      <td>1.196681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780241</th>\n",
       "      <td>1883</td>\n",
       "      <td>23484</td>\n",
       "      <td>5</td>\n",
       "      <td>1.163371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4780242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          iid    uid  rating  prediction\n",
       "0          58  14930       5    1.511545\n",
       "1         624   1747       4    0.805605\n",
       "2           1  14930       3    1.210596\n",
       "3           0   1747       5    1.207255\n",
       "4          16   1747       4    0.994679\n",
       "...       ...    ...     ...         ...\n",
       "4780237   780  10703       4    0.905142\n",
       "4780238  6500  11465       3    1.200742\n",
       "4780239  3408  11465       1    1.385787\n",
       "4780240  6778  11465       3    1.196681\n",
       "4780241  1883  23484       5    1.163371\n",
       "\n",
       "[4780242 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(train, model.user_features, model.item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prospective-tension",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T05:20:56.285343Z",
     "start_time": "2021-02-16T05:20:56.281643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53424, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "italian-spectrum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T05:51:11.629476Z",
     "start_time": "2021-02-16T05:51:11.626098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "available-husband",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T05:51:25.696988Z",
     "start_time": "2021-02-16T05:51:25.694586Z"
    }
   },
   "outputs": [],
   "source": [
    "a = (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "agreed-crack",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T05:51:28.588654Z",
     "start_time": "2021-02-16T05:51:28.585339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "consecutive-spell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:08:29.563255Z",
     "start_time": "2021-02-16T07:08:29.558268Z"
    }
   },
   "outputs": [],
   "source": [
    "alist = [\n",
    "    [1,2,3],\n",
    "    [2,2,4],\n",
    "    [3,2,5],\n",
    "    [1,1,5],\n",
    "    [2,1,1],\n",
    "    [1,3,7],\n",
    "    [2,3,6],\n",
    "    [3,4,1]\n",
    "]\n",
    "a = pd.DataFrame(alist, columns = ['iid', 'uid', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "severe-curve",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:08:31.079425Z",
     "start_time": "2021-02-16T07:08:31.070699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>uid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid  uid  rating\n",
       "0    1    2       3\n",
       "1    2    2       4\n",
       "2    3    2       5\n",
       "3    1    1       5\n",
       "4    2    1       1\n",
       "5    1    3       7\n",
       "6    2    3       6\n",
       "7    3    4       1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tired-device",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:08:49.712998Z",
     "start_time": "2021-02-16T07:08:49.705199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>uid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid  uid  rating\n",
       "0    1    2       3\n",
       "1    2    2       4\n",
       "2    3    2       5\n",
       "3    1    1       5\n",
       "4    2    1       1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a.uid.isin([1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-sunset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
