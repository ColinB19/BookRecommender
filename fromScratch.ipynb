{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chubby-vegetation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T23:09:28.286618Z",
     "start_time": "2021-02-16T23:09:27.995807Z"
    }
   },
   "outputs": [],
   "source": [
    "import msePipeline as mp\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "catholic-ecology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T23:10:08.660937Z",
     "start_time": "2021-02-16T23:09:30.240917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of books in the train set: 10000, test set: 9999, val set: 9998. The number of users in the train set: 53424, test set: 26712, val set: 26712.\n"
     ]
    }
   ],
   "source": [
    "pipeline = mp.MSEPipeline(deploy=False)\n",
    "pipeline.preprocess()\n",
    "train, test, validation = pipeline.split_test_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-digest",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FROM  [here](https://towardsdatascience.com/recommender-systems-matrix-factorization-using-pytorch-bd52f46aa199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-seeking",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:35.998Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_params(df):\n",
    "    \n",
    "    uids = df.uid.unique().tolist()\n",
    "    iids = df.iid.unique().tolist()\n",
    "    num_uid = len(uids)\n",
    "    num_iid = len(iids)\n",
    "    \n",
    "    return uids, iids, num_uid, num_iid\n",
    "\n",
    "def create_embeddings(n, K, gamma = 7):\n",
    "    \"\"\"\n",
    "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
    "    n: number of items/users\n",
    "    K: number of factors in the embedding \n",
    "    \"\"\"\n",
    "    return gamma*np.random.rand(n, K) / K\n",
    "\n",
    "def create_sparse_matrix(df, rows, cols, column_name=\"rating\"):\n",
    "    \"\"\" Returns a sparse utility matrix\"\"\" \n",
    "    return sparse.csc_matrix((df[column_name].values,(df['uid'].values, df['iid'].values)),shape=(rows, cols))\n",
    "\n",
    "def predict(df, emb_user, emb_anime):\n",
    "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
    "    \n",
    "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
    "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
    "    \"\"\"\n",
    "    df['prediction'] = np.sum(np.multiply(emb_anime[df['iid']],emb_user[df['uid']]), axis=1)\n",
    "    return df\n",
    "\n",
    "def cost(df, emb_user, emb_anime):\n",
    "    \"\"\" Computes mean square error\"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_anime), emb_user.shape[0], emb_anime.shape[0], 'prediction')\n",
    "    return np.sum((Y-predicted).power(2))/df.shape[0]\n",
    "\n",
    "def gradient(df, emb_user, emb_anime):\n",
    "    \"\"\" Computes the gradient for user and anime embeddings\"\"\"\n",
    "    lmbda = 0.002\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_anime), emb_user.shape[0], emb_anime.shape[0], 'prediction')\n",
    "    delta =(Y-predicted)\n",
    "    grad_user = (-2/df.shape[0])*(delta*emb_anime) + 2*lmbda*emb_user\n",
    "    grad_anime = (-2/df.shape[0])*(delta.T*emb_user) + 2*lmbda*emb_anime\n",
    "    return grad_user, grad_anime\n",
    "\n",
    "def gradient_descent(df, emb_user, emb_anime, iterations=200, learning_rate=0.05, df_val=None, beta = 0.9, updates = True):\n",
    "    \"\"\" \n",
    "    Computes gradient descent with momentum (0.9) for given number of iterations.\n",
    "    emb_user: the trained user embedding\n",
    "    emb_anime: the trained anime embedding\n",
    "    \"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_anime.shape[0])\n",
    "    grad_user, grad_anime = gradient(df, emb_user, emb_anime)\n",
    "    v_user = grad_user\n",
    "    v_anime = grad_anime\n",
    "    for i in range(iterations):\n",
    "        grad_user, grad_anime = gradient(df, emb_user, emb_anime)\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_anime = beta*v_anime + (1-beta)*grad_anime\n",
    "        emb_user = emb_user - learning_rate*v_user\n",
    "        emb_anime = emb_anime - learning_rate*v_anime\n",
    "        if(not (i+1)%50) and (updates):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  cost(df, emb_user, emb_anime))\n",
    "            if df_val is not None:\n",
    "                print(\"validation mse:\",  cost(df_val, emb_user, emb_anime))\n",
    "    return emb_user, emb_anime, cost(df, emb_user, emb_anime), cost(df_val, emb_user, emb_anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-queensland",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:36.353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uids, iids, num_uid, num_iid = get_params(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-franchise",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:36.708Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Y = create_sparse_matrix(train, num_uid, num_iid)\n",
    "Y.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-business",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:37.044Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_user = create_embeddings(num_uid, 4)\n",
    "emb_anime = create_embeddings(num_iid, 4)\n",
    "emb_user, emb_anime = gradient_descent(train, emb_user, emb_anime, iterations=350, learning_rate=0.1, df_val = validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-parade",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-16T05:08:37.358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def sample_hyperparameters():\n",
    "\n",
    "    return {\n",
    "        \"K\": np.random.randint(10, 20),\n",
    "        \"lr\": np.random.normal(0.05, 0.025),\n",
    "        \"beta\": np.random.normal(0.9, 0.05),\n",
    "        \"gamma\": np.random.randint(5, 15),\n",
    "        \"epochs\": np.random.randint(50, 80)\n",
    "        }      \n",
    "def paramSearch(train, num_uid, num_iid, num_samples = 5):\n",
    "\n",
    "        hyperparams = pd.DataFrame()\n",
    "        print('Searching for optimal parameters...')\n",
    "        for i in tqdm(range(num_samples)):\n",
    "            # get a random sample of hyperparameters\n",
    "            params = sample_hyperparameters()\n",
    "            print(params)\n",
    "            # train a model using those hyperparameters\n",
    "            emb_user = create_embeddings(num_uid, params['K'], gamma = params['gamma'])\n",
    "            emb_item = create_embeddings(num_iid, params['K'], gamma = params['gamma'])\n",
    "            emb_user, emb_item, cost_train, cost_val = gradient_descent(train, \n",
    "                                                                         emb_user, \n",
    "                                                                         emb_item, \n",
    "                                                                         iterations=params['epochs'], \n",
    "                                                                         learning_rate=params['lr'],\n",
    "                                                                         beta = params['beta'], \n",
    "                                                                         df_val = validation,\n",
    "                                                                         updates = False)\n",
    "            params['train_mse'] = cost_train\n",
    "            params['val_mse'] = cost_val\n",
    "            hyperparams = hyperparams.append(params, ignore_index=True)\n",
    "        return hyperparams.sort_values(by = 'val_mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dimensional-convention",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for optimal parameters...\n",
      "{'K': 16, 'lr': 0.06911681421964877, 'beta': 0.8751939500399427, 'gamma': 5, 'epochs': 53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [01:12<10:52, 72.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 14, 'lr': 0.059983531559637523, 'beta': 0.9299892557964924, 'gamma': 6, 'epochs': 79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [02:49<10:38, 79.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 10, 'lr': 0.04015033453193613, 'beta': 0.9194450312942336, 'gamma': 13, 'epochs': 59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [03:54<08:48, 75.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 13, 'lr': 0.061889367038880476, 'beta': 1.0124316673343328, 'gamma': 7, 'epochs': 57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [05:05<07:24, 74.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 18, 'lr': 0.09124107449615401, 'beta': 0.9154476785848042, 'gamma': 5, 'epochs': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [06:39<06:40, 80.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 12, 'lr': 0.09134714584730058, 'beta': 0.8747537042415194, 'gamma': 5, 'epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [07:38<04:54, 73.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 15, 'lr': 0.022424125657719913, 'beta': 0.895327792394344, 'gamma': 14, 'epochs': 58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [08:56<03:44, 74.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 12, 'lr': 0.039828263821539006, 'beta': 0.8090874407948825, 'gamma': 11, 'epochs': 66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [10:13<02:31, 75.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 15, 'lr': 0.04029155477339579, 'beta': 0.8854276678463482, 'gamma': 14, 'epochs': 77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [11:55<01:23, 83.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 18, 'lr': 0.01829605681505877, 'beta': 0.8838056958032741, 'gamma': 11, 'epochs': 76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:48<00:00, 82.86s/it]\n"
     ]
    }
   ],
   "source": [
    "hp = paramSearch(train, num_uid, num_iid, num_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "irish-norwegian",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>beta</th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.895328</td>\n",
       "      <td>58.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>1.955910</td>\n",
       "      <td>1.955168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.885428</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.040292</td>\n",
       "      <td>2.040690</td>\n",
       "      <td>2.043973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.919445</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.040150</td>\n",
       "      <td>2.360247</td>\n",
       "      <td>2.369465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.809087</td>\n",
       "      <td>66.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.039828</td>\n",
       "      <td>3.476850</td>\n",
       "      <td>3.468857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.883806</td>\n",
       "      <td>76.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>6.176782</td>\n",
       "      <td>6.153494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.012432</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>10.005748</td>\n",
       "      <td>9.978112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.929989</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.059984</td>\n",
       "      <td>11.811594</td>\n",
       "      <td>11.785822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.091347</td>\n",
       "      <td>12.618779</td>\n",
       "      <td>12.587218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.875194</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>13.479378</td>\n",
       "      <td>13.445336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.915448</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>13.801077</td>\n",
       "      <td>13.768661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      K      beta  epochs  gamma        lr  train_mse    val_mse\n",
       "6  15.0  0.895328    58.0   14.0  0.022424   1.955910   1.955168\n",
       "8  15.0  0.885428    77.0   14.0  0.040292   2.040690   2.043973\n",
       "2  10.0  0.919445    59.0   13.0  0.040150   2.360247   2.369465\n",
       "7  12.0  0.809087    66.0   11.0  0.039828   3.476850   3.468857\n",
       "9  18.0  0.883806    76.0   11.0  0.018296   6.176782   6.153494\n",
       "3  13.0  1.012432    57.0    7.0  0.061889  10.005748   9.978112\n",
       "1  14.0  0.929989    79.0    6.0  0.059984  11.811594  11.785822\n",
       "5  12.0  0.874754    50.0    5.0  0.091347  12.618779  12.587218\n",
       "0  16.0  0.875194    53.0    5.0  0.069117  13.479378  13.445336\n",
       "4  18.0  0.915448    64.0    5.0  0.091241  13.801077  13.768661"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "studied-findings",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  iid  rating\n",
       "0    1    1       4\n",
       "1    1    4       5\n",
       "2    4    7       1\n",
       "3    7    2       4\n",
       "4    7    1       2\n",
       "5    9    9       4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testList = [\n",
    "    [1,1,4],\n",
    "    [1,4,5],\n",
    "    [4,7,1],\n",
    "    [7,2,4],\n",
    "    [7,1,2],\n",
    "    [9,9,4]\n",
    "]\n",
    "\n",
    "vec = [np.random.randint(1,10) for _ in range(10)]\n",
    "\n",
    "testListdf = pd.DataFrame(testList, columns = ['uid', 'iid', 'rating'])\n",
    "testListdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fitted-landscape",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 5, 7, 2, 9, 1, 7, 9, 6]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "stretch-territory",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testSparse = sparse.csc_matrix((testListdf['rating'].values,(testListdf['uid'].values, testListdf['iid'].values)),shape=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "center-moldova",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 26,  0,  0,  7,  0,  0, 28,  0, 24])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSparse.dot(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-translation",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## My own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "independent-porcelain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T00:52:52.137188Z",
     "start_time": "2021-02-16T00:52:52.085242Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 10000 books and 53424  users.\n"
     ]
    }
   ],
   "source": [
    "num_items = len(train.iid.unique())\n",
    "num_users = len(train.uid.unique())\n",
    "\n",
    "print(f\"The training set has {num_items} books and {num_users}  users.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-federation",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Step 1\n",
    "\n",
    "First I want to create the matrices with which I can perform gradient descent. I'll need \n",
    "   1. Feature embeddings $\\bf{A}$ and $\\bf{B}$, initialized randomly.\n",
    "   2. A sparse user-item interaction matrix $\\bf{Y}$ (also known as the utility matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "solar-union",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T01:47:23.980920Z",
     "start_time": "2021-02-16T01:47:23.671017Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for now let's just have 10 features (K=10)\n",
    "K=10 # this is a hyperparameter that should be tuned\n",
    "alpha=11 # this is a hyperparameter that should be tuned\n",
    "\n",
    "user_features = np.random.uniform(0,alpha/K,(num_users,K))\n",
    "item_features = np.random.uniform(0,alpha/K,(num_items,K))\n",
    "\n",
    "utility = sparse.csc_matrix((train.rating.values, (train.uid.values, train.iid.values)), shape=(num_users, num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-preview",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T01:01:53.297298Z",
     "start_time": "2021-02-16T01:01:53.292161Z"
    },
    "hidden": true
   },
   "source": [
    "### Step 2\n",
    "\n",
    "Now we need a cost function and it's gradient. Let's go with mean square error (MSE) for now. For us MSE looks like\n",
    "\n",
    "$$ \\textbf{MSE} = \\frac{1}{N}\\sum_{i,j}^{N} (y_{ij} - a_{ik}b_{kj})^2 $$ \n",
    "\n",
    "where $N$ is the number of non-null entries in the utility matrix. Note that the lower case names of the utility and embedded matrices represent the indexed entries of each matrix. Capital and bolded letters indicate a matrix representation of the objects. Repeated indices imply summation. \n",
    "\n",
    "If we include regularization in this loss function, we get:\n",
    "\n",
    "$$ \\textbf{L} = \\textbf{MSE} + \\lambda_a a_{\\ell m}a_{m \\ell} +  \\lambda_b b_{\\ell m}b_{m \\ell} $$. \n",
    "\n",
    "Where $\\lambda_a$ and $\\lambda_b$ are just regularization parameters. As it turns out, the matrix $\\bf{A} \\bf{B}^{T}$ is a large matrix. We can avoid computing it by just computing each prediction row individually and adding it to the training DataFrame as a new column, then we can create a sparse matrix from that! Just as in [here](https://towardsdatascience.com/recommender-systems-matrix-factorization-using-pytorch-bd52f46aa199). In fact, our `predict` method will be more or less the same. The gradient of this function is fairly simple to compute:\n",
    "\n",
    "$$ \\vec{\\nabla} \\textbf{L} = -2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "waiting-console",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:43:44.254523Z",
     "start_time": "2021-02-16T03:43:44.246238Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict(df, user_features, item_features):\n",
    "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
    "    \n",
    "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
    "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
    "    \"\"\"\n",
    "    df['prediction'] = np.sum(np.multiply(item_features[df['iid']],user_features[df['uid']]), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def meanSquareError(df, utility, user_features, item_features):\n",
    "    '''\n",
    "    This function computes the MSE for a given set of feature matrices. Remember we never hold the \n",
    "    prediction utility matrix. We add a prediction column to the pandas dataframe then create a sparse\n",
    "    matrix of predictions when we need it.\n",
    "    '''\n",
    "    temp = predict(train, user_features=user_features, item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                       shape=(user_features.shape[0], item_features.shape[0]))\n",
    "    error = utility-prediction\n",
    "    return (1/len(df))*np.sum(error.power(2))\n",
    "\n",
    "def gradient_reg(df, utility, user_features, item_features, lmbda_a, lmbda_b):\n",
    "    '''\n",
    "    This function computes the regularized gradient.\n",
    "    '''\n",
    "    temp = predict(train, user_features=user_features, item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                       shape=(user_features.shape[0], item_features.shape[0]))\n",
    "    error = utility-prediction\n",
    "    grad_user = (-2/df.shape[0])*(error*item_features) + 2*lmbda_a*user_features\n",
    "    grad_item = (-2/df.shape[0])*((error.T)*user_features) + 2*lmbda_b*item_features\n",
    "    return grad_user, grad_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "happy-shell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:30:50.660600Z",
     "start_time": "2021-02-16T03:30:49.772284Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5527136723429513"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = MSE(df = train, utility = utility, user_features = user_features, item_features = item_features)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "defensive-nightlife",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:30:51.597614Z",
     "start_time": "2021-02-16T03:30:50.662391Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53424, 10000) (53424, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "test = gradient_reg(df = train, utility = utility, user_features = user_features, item_features = item_features,\n",
    "                   lmbda_a = 0.0002, lmbda_b=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "outstanding-regular",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:43:24.525295Z",
     "start_time": "2021-02-16T03:43:24.517632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(df, \n",
    "                    utility, \n",
    "                    user_features, \n",
    "                    item_features, \n",
    "                    lmbda_a=0.002, \n",
    "                    lmbda_b=0.002,\n",
    "                    utility_val=None, \n",
    "                    iterations=10, \n",
    "                    learning_rate=0.05, \n",
    "                    beta=0.9, \n",
    "                    updates=True):\n",
    "\n",
    "    grad_user, grad_item = gradient_reg(df=df, \n",
    "                                        utility=utility, \n",
    "                                        user_features=user_features, \n",
    "                                        item_features=item_features, \n",
    "                                        lmbda_a=lmbda_a,\n",
    "                                        lmbda_b=lmbda_b)\n",
    "    v_user = grad_user\n",
    "    v_item = grad_item\n",
    "    for i in range(iterations):\n",
    "        grad_user, grad_item = gradient_reg(df=df, \n",
    "                                            utility=utility, \n",
    "                                            user_features=user_features, \n",
    "                                            item_features=item_features, \n",
    "                                            lmbda_a=lmbda_a,\n",
    "                                            lmbda_b=lmbda_b)\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_item = beta*v_item + (1-beta)*grad_item\n",
    "        user_features = user_features - learning_rate*v_user\n",
    "        item_features = item_features - learning_rate*v_item\n",
    "        if(not (i+1) % 50) and (updates):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  meanSquareError(df, utility, user_features, item_features))\n",
    "            if utility_val is not None:\n",
    "                print(\"validation mse:\",  meanSquareError(df, utility_val, user_features, item_features))\n",
    "\n",
    "    if utility_val:\n",
    "        return user_features, item_features, meanSquareError(df, utility, user_features, item_features), meanSquareError(utility_val, user_features, item_features)\n",
    "    else:\n",
    "        return user_features, item_features, meanSquareError(df, utility, user_features, item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "social-murray",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T03:44:14.728270Z",
     "start_time": "2021-02-16T03:44:05.014680Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "meanSquareError() missing 1 required positional argument: 'item_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-23c939e4af93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-e1ad153e9067>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(df, utility, user_features, item_features, lmbda_a, lmbda_b, utility_val, iterations, learning_rate, beta, updates)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanSquareError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: meanSquareError() missing 1 required positional argument: 'item_features'"
     ]
    }
   ],
   "source": [
    "gradient_descent(df = train, utility = utility, user_features = user_features, item_features = item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-sweet",
   "metadata": {},
   "source": [
    "## My own from file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-madonna",
   "metadata": {},
   "source": [
    "### defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "competent-safety",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:52:57.327968Z",
     "start_time": "2021-02-17T09:52:57.297184Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_sparse_matrix(df, rows, cols, column_name=\"rating\"):\n",
    "    ''' \n",
    "    Creates a scipy sparse matrix\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        The data that will be made a sparse matrix\n",
    "    rows : int\n",
    "        number of rows in the matrix\n",
    "    columns : int\n",
    "        number of columns in the matrix\n",
    "    column_name : \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    '''\n",
    "    return sparse.csc_matrix((df[column_name].values, (df['uid'].values, df['iid'].values)), shape=(rows, cols))\n",
    "\n",
    "\n",
    "def create_embeddings(n, K, gamma=7):\n",
    "    ''' \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    '''\n",
    "    return gamma*np.random.rand(n, K) / K\n",
    "\n",
    "def predict(df, user_features, item_features):\n",
    "    ''' \n",
    "    This function performs the element wise prediction of each item for each user. It avoids building the \n",
    "    approximated utility matrix in order to save space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas DataFrame\n",
    "        The same dataframe as inputted but with a new/updated predictions column. \n",
    "\n",
    "    '''\n",
    "    df['prediction'] = np.sum(np.multiply(\n",
    "        item_features[df['iid']], user_features[df['uid']]), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def meanSquareError(df, user_features, item_features):\n",
    "    ''' \n",
    "    Computes the mean square error on the predictions. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mse : float\n",
    "        The mean square error for the given embedding matrices. \n",
    "\n",
    "    '''\n",
    "    # we need to actually make predictions then convert those into a sparse matrix\n",
    "    utility = create_sparse_matrix(df, user_features.shape[0], item_features.shape[0])\n",
    "    temp = predict(df=df, user_features=user_features,\n",
    "                   item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                   shape=(user_features.shape[0], item_features.shape[0]))\n",
    "\n",
    "    # now let's get an error matrix then return the MSE.\n",
    "    error = utility-prediction\n",
    "    mse = (1/len(df))*np.sum(error.power(2))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def gradient_reg(df, utility, user_features, item_features, lmbda_a, lmbda_b):\n",
    "    ''' \n",
    "    Computes the regularized gradient of the mean square error. Returns the gradient\n",
    "    in the 'directions' of both embedded matrices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    utility : scipy sparse matrix\n",
    "        The sparse utility matrix of all of the ratings.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "    lmbda_a, lmbda_b : float\n",
    "        These parameters are the regularization coefficients. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grad_user : numpy array\n",
    "        gradient of the MSE, partial derivative w.r.t. the user \n",
    "    grad_item : numpy array\n",
    "        gradient of the MSE, partial derivative w.r.t. the item \n",
    "\n",
    "    '''\n",
    "    # we need to actually make predictions then convert those into a sparse matrix\n",
    "    temp = predict(df=df, user_features=user_features,\n",
    "                   item_features=item_features)\n",
    "    prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
    "                                   shape=(user_features.shape[0], item_features.shape[0]))\n",
    "    # now let's get an error matrix\n",
    "    error = utility-prediction\n",
    "\n",
    "    # we can now compute the gradient \n",
    "    # we will compute each 'direction' separately and return them separately\n",
    "    grad_user = (-2/df.shape[0]) * (error*item_features) + 2*lmbda_a*user_features\n",
    "    grad_item = (-2/df.shape[0])*((error.T) * user_features) + 2*lmbda_b*item_features\n",
    "    return grad_user, grad_item\n",
    "\n",
    "\n",
    "def gradient_descent(df,\n",
    "                     utility,\n",
    "                     user_features,\n",
    "                     item_features,\n",
    "                     val=None,\n",
    "                     lmbda_a=0.002,\n",
    "                     lmbda_b=0.002,\n",
    "                     epochs=200,\n",
    "                     learning_rate=0.05,\n",
    "                     beta=0.9,\n",
    "                     updates=True,\n",
    "                     dfError=None\n",
    "                    ):\n",
    "    ''' \n",
    "    Performs gradient descent to find the optimal embedded matrices. A momentum term\n",
    "    is added to arrive at the minimum sooner. This function will iterate a number of times\n",
    "    specified by the user. It will update the user every 50 epochs on how the cost function \n",
    "    looks. Finally it will return the new embedded matrices and the final cost values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        This is the pandas dataframe of the data predictions are to be made on.\n",
    "    utility : scipy sparse matrix\n",
    "        The sparse utility matrix of all of the ratings.\n",
    "    user_features : numpy array\n",
    "        The user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The item feature embeddings.\n",
    "    val : pandas DataFrame DEFAULT=None\n",
    "        The validation set to check the algorithm against.\n",
    "    lmbda_a, lmbda_b : float, DEFAULT=0.002 for both\n",
    "        These parameters are the regularization coefficients. \n",
    "    epochs : int, DEFAULT=200\n",
    "        The number of iterations on which to perform GD\n",
    "    learning_rate : float, DEFAULT=0.05\n",
    "        The learning rate for GD.\n",
    "    beta : float, DEFAULT=0.9\n",
    "        The momentum coefficient.\n",
    "    updates: bool, DEFAULT=True\n",
    "        The option to print periodic updates of the MSE as the algorithm runs.\n",
    "        Updates will print every epoch with the MSE of the set. It will give\n",
    "        the MSE of the validation set if provided.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    user_features : numpy array\n",
    "        The optimized user feature embeddings.\n",
    "    item_features : numpy Array\n",
    "        The optimized item feature embeddings.\n",
    "    mse_train : float\n",
    "        The final MSE of the training set\n",
    "    mse_val : float, OPTIONAL\n",
    "        the final MSE of the validation set\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    # get the initial gradient term so we can perform the first\n",
    "    # round of GD. Needed for momentum terms\n",
    "    grad_user, grad_item = gradient_reg(df=df,\n",
    "                                        utility=utility,\n",
    "                                        user_features=user_features,\n",
    "                                        item_features=item_features,\n",
    "                                        lmbda_a=lmbda_a,\n",
    "                                        lmbda_b=lmbda_b)\n",
    "    v_user = grad_user\n",
    "    v_item = grad_item\n",
    "    for i in range(epochs):\n",
    "        # update the gradient based on new feature matrices\n",
    "        grad_user, grad_item = gradient_reg(df=df,\n",
    "                                            utility=utility,\n",
    "                                            user_features=user_features,\n",
    "                                            item_features=item_features,\n",
    "                                            lmbda_a=lmbda_a,\n",
    "                                            lmbda_b=lmbda_b)\n",
    "\n",
    "        # compute our update matrices\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_item = beta*v_item + (1-beta)*grad_item\n",
    "\n",
    "        # update the embedded matrices\n",
    "#         user_features = user_features - learning_rate*v_user\n",
    "#         item_features = item_features - learning_rate*v_item\n",
    "        \n",
    "        user_features = user_features - learning_rate*grad_user\n",
    "        item_features = item_features - learning_rate*grad_item\n",
    "\n",
    "        # just print out values every so often to see what is happening \n",
    "        # with the algo.\n",
    "        if(not (i+1) % 50) and (updates):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  meanSquareError(\n",
    "                df, user_features, item_features))\n",
    "            if val is not None:\n",
    "                print(\"validation mse:\",  meanSquareError(\n",
    "                    val, user_features, item_features))\n",
    "        if dfError is not None:\n",
    "            dfError = dfError.append(meanSquareError(df, user_features, item_features))\n",
    "\n",
    "    # compute the final MSE\n",
    "    mse_train = meanSquareError(df, user_features, item_features)\n",
    "\n",
    "    # here we just check if the validation set is passed in so we can return the final cost of that as well if needed.\n",
    "    if val is not None:\n",
    "        mse_val = meanSquareError(val, user_features, item_features)\n",
    "        if dfError is not None:\n",
    "                return (user_features, item_features, mse_train, mse_val, dfError)\n",
    "        return (user_features, item_features, mse_train, mse_val)\n",
    "    if dfError is not None: \n",
    "        return (user_features, item_features, mse_train, dfError)\n",
    "    return (user_features, item_features, mse_train)\n",
    "\n",
    "\n",
    "def sample_hyperparameters():\n",
    "    ''' \n",
    "    This function returns a random value for each hyperparameter for MSE gradient descent. \n",
    "    '''\n",
    "    return {\n",
    "        \"K\": np.random.randint(10, 50),\n",
    "        \"lr\": np.random.uniform(0.01, 0.3),\n",
    "        \"beta\": np.random.uniform(0.9, 0.99),\n",
    "        \"gamma\": np.random.randint(5, 40),\n",
    "        \"epochs\": np.random.randint(50, 400)\n",
    "    }\n",
    "\n",
    "\n",
    "class MSErec():\n",
    "    '''\n",
    "    This class will perform all ML processes to predict books for users of our app. It will create \n",
    "    user/item matrices, perform gradient descent (with momentum), and output predictions!\n",
    "    '''\n",
    "\n",
    "    def __init__(self, df, test=None, validation=None):\n",
    "        ''' \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "        # let's create a class dataframe object first\n",
    "        self.df=df\n",
    "        \n",
    "        num_uid = len(df.uid.unique())\n",
    "        num_iid = len(df.iid.unique())\n",
    "\n",
    "        # create sparse matrices\n",
    "        self.utility = create_sparse_matrix(df, num_uid, num_iid)\n",
    "        # only create matrices for test and val if passed\n",
    "        if test:\n",
    "            self.test = create_sparse_matrix(test, num_uid, num_iid)\n",
    "        else:\n",
    "            self.test = None\n",
    "        if validation:\n",
    "            self.validation = create_sparse_matrix(validation, num_uid, num_iid)\n",
    "        else:\n",
    "            self.validation = None\n",
    "    \n",
    "\n",
    "    def trainModel(self, K=15, beta=0.90, epochs=60, gamma=14, lr=0.025):\n",
    "        ''' \n",
    "        optimal : K=15, beta=0.90, epochs=60, gamma=14, lr=0.025\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "        # this initializes some embedding matrices\n",
    "        num_uid = self.utility.shape[0]\n",
    "        num_iid = self.utility.shape[1]\n",
    "        self.user_features = create_embeddings(num_uid, K=K, gamma=gamma)\n",
    "        self.item_features = create_embeddings(num_iid, K=K, gamma=gamma)\n",
    "        \n",
    "        # now perform GD, check if we passed a validation set as well.\n",
    "        if self.validation is not None:\n",
    "            self.emb_user, self.emb_item, cost_train, cost_val = gradient_descent(df = self.df,\n",
    "                                                                              utility = self.utility,\n",
    "                                                                              user_features = self.user_features,\n",
    "                                                                              item_features = self.item_features,\n",
    "                                                                              epochs=epochs,\n",
    "                                                                              val = self.validation,\n",
    "                                                                              learning_rate = lr,\n",
    "                                                                              updates=False)\n",
    "            return (cost_train, cost_val)\n",
    "    \n",
    "        else:\n",
    "            self.emb_user, self.emb_item, cost_train = gradient_descent(df = self.df,\n",
    "                                                                      utility = self.utility,\n",
    "                                                                      user_features = self.user_features,\n",
    "                                                                      item_features = self.item_features,\n",
    "                                                                      learning_rate = lr,\n",
    "                                                                      epochs=epochs,\n",
    "                                                                      updates=False)\n",
    "            return (cost_train,)\n",
    "\n",
    "    def paramSearch(self, num_samples=5):\n",
    "        ''' \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        '''\n",
    "        hyperparams = pd.DataFrame()\n",
    "        print('Searching for optimal parameters...')\n",
    "        for i in tqdm(range(num_samples)):\n",
    "            # get a random sample of hyperparameters\n",
    "            params = sample_hyperparameters()\n",
    "            cost = self.trainModel(K=params[\"K\"],\n",
    "                                   beta=params[\"beta\"], \n",
    "                                   epochs=params[\"epochs\"], \n",
    "                                   gamma=params[\"gamma\"], \n",
    "                                   lr=params[\"lr\"])\n",
    "            \n",
    "            params['train_mse'] = cost[0]   \n",
    "            if len(cost)==2:\n",
    "                params['val_mse'] = cost[1]\n",
    "            hyperparams = hyperparams.append(params, ignore_index=True)\n",
    "            \n",
    "        return hyperparams.sort_values(by='train_mse')\n",
    "    \n",
    "    def gridSearch(self, dfParams):\n",
    "        Ks = [20,25,30]\n",
    "        epochs=[100,125,150]\n",
    "        gammas = [15,20,25]\n",
    "        lrs = [0.025, 0.05,0.075]\n",
    "        for k in Ks:\n",
    "            for gamma in gammas:\n",
    "                for epoch in tqdm(epochs):\n",
    "                    for lr in lrs:\n",
    "                        dfError = pd.DataFrame()\n",
    "                        # this initializes some embedding matrices\n",
    "                        num_uid = self.utility.shape[0]\n",
    "                        num_iid = self.utility.shape[1]\n",
    "                        self.user_features = create_embeddings(num_uid, K=k, gamma=gamma)\n",
    "                        self.item_features = create_embeddings(num_iid, K=k, gamma=gamma)\n",
    "\n",
    "                        self.emb_user, self.emb_item, cost_train, dfError = gradient_descent(df = self.df,\n",
    "                                                                                    utility = self.utility,\n",
    "                                                                                    user_features = self.user_features,\n",
    "                                                                                    item_features = self.item_features,\n",
    "                                                                                    epochs=epoch,\n",
    "                                                                                    learning_rate = lr,\n",
    "                                                                                    updates=False,\n",
    "                                                                                    dfError=dfError)\n",
    "                    dfParams = dfParams.append([[epoch, lr, cost_train]])\n",
    "                dfError.to_csv(f\"AnalyzedData/error_E{epoch}_L{lr}_K{k}_G{gamma}.csv\")\n",
    "        return dfParams   \n",
    "                \n",
    "        \n",
    "    \n",
    "    def getPredictions(self):\n",
    "        self.df = predict(df = self.df, \n",
    "                          user_features = self.user_features, \n",
    "                          item_features = self.item_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-leader",
   "metadata": {},
   "source": [
    "### testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hazardous-standing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T23:10:29.323431Z",
     "start_time": "2021-02-16T23:10:28.963174Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MSErec(df = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charged-living",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T03:14:17.712149Z",
     "start_time": "2021-02-16T23:10:30.235761Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for optimal parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [4:03:47<00:00, 487.58s/it]  \n"
     ]
    }
   ],
   "source": [
    "hypers=model.paramSearch(num_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prospective-tension",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T03:43:56.214630Z",
     "start_time": "2021-02-17T03:43:56.207035Z"
    }
   },
   "outputs": [],
   "source": [
    "hypers.to_csv(\"hyperparameters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documented-yemen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T05:19:23.173207Z",
     "start_time": "2021-02-17T05:19:23.155901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>beta</th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.968173</td>\n",
       "      <td>224.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>1.384212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.944731</td>\n",
       "      <td>237.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.231834</td>\n",
       "      <td>1.583662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.936930</td>\n",
       "      <td>231.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.153167</td>\n",
       "      <td>1.687742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.933398</td>\n",
       "      <td>377.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.155688</td>\n",
       "      <td>1.853979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.984816</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.220418</td>\n",
       "      <td>2.869121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.946832</td>\n",
       "      <td>291.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.177202</td>\n",
       "      <td>3.065484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.987146</td>\n",
       "      <td>294.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.077751</td>\n",
       "      <td>3.525451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.900630</td>\n",
       "      <td>73.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.100183</td>\n",
       "      <td>3.832261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.971618</td>\n",
       "      <td>395.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.095283</td>\n",
       "      <td>4.137352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.940970</td>\n",
       "      <td>160.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.121723</td>\n",
       "      <td>4.985146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.961974</td>\n",
       "      <td>324.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.269863</td>\n",
       "      <td>5.348285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.963023</td>\n",
       "      <td>299.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.203750</td>\n",
       "      <td>6.631204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.978604</td>\n",
       "      <td>210.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.159580</td>\n",
       "      <td>6.785110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.903194</td>\n",
       "      <td>124.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.209109</td>\n",
       "      <td>7.010523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.963653</td>\n",
       "      <td>271.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.140957</td>\n",
       "      <td>7.870526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.970533</td>\n",
       "      <td>183.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.255983</td>\n",
       "      <td>8.045451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.928518</td>\n",
       "      <td>228.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.110926</td>\n",
       "      <td>8.123670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.933390</td>\n",
       "      <td>171.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.238324</td>\n",
       "      <td>8.986312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.981224</td>\n",
       "      <td>272.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.037008</td>\n",
       "      <td>9.123116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.901351</td>\n",
       "      <td>396.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.155880</td>\n",
       "      <td>9.246831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.943543</td>\n",
       "      <td>68.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.060159</td>\n",
       "      <td>11.324085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.908859</td>\n",
       "      <td>285.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.118034</td>\n",
       "      <td>11.493234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.959571</td>\n",
       "      <td>212.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.088573</td>\n",
       "      <td>12.526440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.972319</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.030913</td>\n",
       "      <td>13.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.943928</td>\n",
       "      <td>301.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>14.343251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.980491</td>\n",
       "      <td>196.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.168382</td>\n",
       "      <td>20.363040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.919805</td>\n",
       "      <td>398.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.217363</td>\n",
       "      <td>40.819181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.940974</td>\n",
       "      <td>245.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>71.744410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.944625</td>\n",
       "      <td>72.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.145590</td>\n",
       "      <td>112.898554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>215.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.095639</td>\n",
       "      <td>141.484294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       K      beta  epochs  gamma        lr   train_mse\n",
       "18  27.0  0.968173   224.0   21.0  0.012791    1.384212\n",
       "4   40.0  0.944731   237.0   28.0  0.231834    1.583662\n",
       "19  49.0  0.936930   231.0   26.0  0.153167    1.687742\n",
       "12  34.0  0.933398   377.0   22.0  0.155688    1.853979\n",
       "20  35.0  0.984816    59.0   27.0  0.220418    2.869121\n",
       "9   36.0  0.946832   291.0   20.0  0.177202    3.065484\n",
       "11  39.0  0.987146   294.0   31.0  0.077751    3.525451\n",
       "10  21.0  0.900630    73.0   14.0  0.100183    3.832261\n",
       "1   38.0  0.971618   395.0   32.0  0.095283    4.137352\n",
       "5   40.0  0.940970   160.0   18.0  0.121723    4.985146\n",
       "22  40.0  0.961974   324.0   18.0  0.269863    5.348285\n",
       "3   25.0  0.963023   299.0   13.0  0.203750    6.631204\n",
       "28  45.0  0.978604   210.0   17.0  0.159580    6.785110\n",
       "24  42.0  0.903194   124.0   16.0  0.209109    7.010523\n",
       "16  46.0  0.963653   271.0   16.0  0.140957    7.870526\n",
       "21  26.0  0.970533   183.0   27.0  0.255983    8.045451\n",
       "26  13.0  0.928518   228.0   19.0  0.110926    8.123670\n",
       "27  43.0  0.933390   171.0   14.0  0.238324    8.986312\n",
       "23  49.0  0.981224   272.0   39.0  0.037008    9.123116\n",
       "17  33.0  0.901351   396.0   33.0  0.155880    9.246831\n",
       "29  47.0  0.943543    68.0   37.0  0.060159   11.324085\n",
       "7   28.0  0.908859   285.0    9.0  0.118034   11.493234\n",
       "14  37.0  0.959571   212.0    9.0  0.088573   12.526440\n",
       "2   21.0  0.972319   165.0    6.0  0.030913   13.275556\n",
       "13  32.0  0.943928   301.0    6.0  0.072400   14.343251\n",
       "6   41.0  0.980491   196.0   39.0  0.168382   20.363040\n",
       "0   16.0  0.919805   398.0   29.0  0.217363   40.819181\n",
       "15  22.0  0.940974   245.0   36.0  0.028889   71.744410\n",
       "8   25.0  0.944625    72.0   39.0  0.145590  112.898554\n",
       "25  18.0  0.989011   215.0   37.0  0.095639  141.484294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I want to do a grid search right around the best one. \n",
    "# for this I want to plot the MSE as I train to see what's going on\n",
    "hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "standing-summer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T08:51:45.068639Z",
     "start_time": "2021-02-17T08:51:44.743451Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MSErec(df = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "characteristic-delight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:30:09.019829Z",
     "start_time": "2021-02-17T08:51:45.086565Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [38:23<1:16:47, 2303.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f0f8c1feb627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdfError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-5c4a800fa2ee>\u001b[0m in \u001b[0;36mgridSearch\u001b[0;34m(self, dfParams, dfError)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 self.emb_user, self.emb_item, cost_train, dfError = gradient_descent(df = self.df,\n\u001b[0m\u001b[1;32m    381\u001b[0m                                                                             \u001b[0mutility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                                                                             \u001b[0muser_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-5c4a800fa2ee>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(df, utility, user_features, item_features, val, lmbda_a, lmbda_b, epochs, learning_rate, beta, updates, dfError)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# update the gradient based on new feature matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         grad_user, grad_item = gradient_reg(df=df,\n\u001b[0m\u001b[1;32m    208\u001b[0m                                             \u001b[0mutility\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                                             \u001b[0muser_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-5c4a800fa2ee>\u001b[0m in \u001b[0;36mgradient_reg\u001b[0;34m(df, utility, user_features, item_features, lmbda_a, lmbda_b)\u001b[0m\n\u001b[1;32m    121\u001b[0m     '''\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# we need to actually make predictions then convert those into a sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     temp = predict(df=df, user_features=user_features,\n\u001b[0m\u001b[1;32m    124\u001b[0m                    item_features=item_features)\n\u001b[1;32m    125\u001b[0m     prediction = sparse.csc_matrix((temp.prediction.values, (temp.uid.values, temp.iid.values)),\n",
      "\u001b[0;32m<ipython-input-32-5c4a800fa2ee>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(df, user_features, item_features)\u001b[0m\n\u001b[1;32m     58\u001b[0m     '''\n\u001b[1;32m     59\u001b[0m     df['prediction'] = np.sum(np.multiply(\n\u001b[0;32m---> 60\u001b[0;31m         item_features[df['iid']], user_features[df['uid']]), axis=1)\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfParams = pd.DataFrame(columns = ['epochs', 'lr', 'cost'])\n",
    "dfParams = model.gridSearch(dfParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "popular-alfred",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T07:52:44.605596Z",
     "start_time": "2021-02-17T07:52:44.598350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.462501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.424707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.464136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.454530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.433262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.453236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  200.000000\n",
       "1    0.010000\n",
       "2    1.462501\n",
       "0  200.000000\n",
       "1    0.050000\n",
       "2    1.424707\n",
       "0  225.000000\n",
       "1    0.010000\n",
       "2    1.464136\n",
       "0  225.000000\n",
       "1    0.050000\n",
       "2    1.454530\n",
       "0  250.000000\n",
       "1    0.010000\n",
       "2    1.433262\n",
       "0  250.000000\n",
       "1    0.050000\n",
       "2    1.453236"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "disabled-assurance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T06:38:26.862829Z",
     "start_time": "2021-02-17T06:38:26.856818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1\n",
       "0  1  10\n",
       "0  2   9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-mentor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
